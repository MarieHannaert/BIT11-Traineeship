configfile: "config.yaml"

rule all:
    input:
        expand("results/00_fastqc/", sample=config["samples"]),
        expand("results/02_kraken2/{sample}_kraken2.report", sample=config["samples"]),
        expand("results/03_krona/{sample}_krona.html", sample=config["samples"]),
        expand("results/04_fastp/{sample}_1.fq.gz", sample=config["samples"]),
        expand("results/04_fastp/{sample}_2.fq.gz", sample=config["samples"]),
        expand("results/05_shovill/{sample}/contigs.fa", sample=config["samples"]),
        expand("results/assemblies/{sample}.fna", sample=config["samples"]),
        "results/06_skani/skani_results_file.txt",
        "results/07_quast/quast_summary_table.txt",
        "results/busco_summaries",
        expand("results/08_busco/{sample}/", sample=config["samples"])


def get_all_samples(wildcards):
    samples = []
    for sample_group in config["samples"]:
        samples.extend(config["samples"][sample_group].values())
    return samples

def get_samples_group_1(wildcards):
    return list(config["samples"]["samples_1"].values())

def get_samples_group_2(wildcards):
    return list(config["samples"]["samples_2"].values())


rule fastqc: 
    input: 
        get_all_samples
    output: 
        directory("results/00_fastqc/")
    params: 
        extra= "-t 32"
    log:
        "logs/fastqc.log"
    shell:
        """
        fastqc {params.extra} {input} --extract -o {output} 2>> {log}
        """

rule multiqc: 
    input: 
        "results/00_fastqc/"
    output: 
        directory("results/01_multiqc/")
    log: 
        "logs/multiqc.log"
    conda:
        "envs/multiqc.yml"
    shell:
        """
        multiqc {input} 2>> {log}
        rm -rf {input} 2>> {log}
        mv {input}/multiqc_report.html {output}
        """

rule Kraken2:
    input:
        get_all_samples
    output:
        report="results/02_kraken2/{sample}_kraken2.report"
    params:
        threads=16
    log:
        "logs/Kraken2_{sample}.log"
    shell:
        """
        kraken2 --gzip-compressed {input} --db /var/db/kraken2/Standard --report {output.report} --threads {params.threads} --quick --memory-mapping 2>> {log}
        """

rule Krona:
    input:
        report="results/02_kraken2/{sample}_kraken2.report"
    output:
        html="results/03_krona/{sample}_krona.html"
    params:
        extra="-t 5 -m 3"
    log:
        "logs/Krona_{sample}.log"
    conda:
        "envs/krona.yml"
    shell:
        """
        ktImportTaxonomy {params.extra} -o {output.html} {input.report} 2>> {log}
        mv {output.html}.html {output.html}
        """

rule fastp:
    input:
        first= get_samples_group_1,
        second= get_samples_group_2
    output:
        first= "results/04_fastp/{sample}_1.fq.gz",
        second= "results/04_fastp/{sample}_2.fq.gz",
        html= "results/04_fastp/{sample}_fastp.html",
        json= "results/04_fastp/{sample}_fastp.json"

    params:
        extra= "-w 32"
    log:
        "logs/fastp.log"
    shell:
        """
        fastp {params.extra} -i {input.first} -I {input.second} -o {output.first} -O {output.second} -h {output.html} -j {output.json} --detect_adapter_for_pe 2>> {log}
        """

rule shovill:
    input: 
        first= "results/04_fastp/{sample}_1.fq.gz",
        second= "results/04_fastp/{sample}_2.fq.gz"
    output: 
        directory("results/05_shovill/{sample}")
    params:
        extra= "--cpus 16 --ram 16 --minlen 500 --trim"
    log: 
        "logs/shovill.log"
    conda:
        "envs/shovill.yml"
    shell:
        """
        shovill --R1 {input.first} --R2 {input.second} {params.extra} -outdir {output}
        """

rule assemblies:
    input: 
        copie= directory("results/05_shovill"),
        remove= expand("results/04_fastp/{{sample}}_{read}.fq.gz", read=["1", "2"])
    output: 
        "results/assemblies/{sample}.fna"
    shell:
        """
        for d in $(ls -d {input.copie}/*/); do cp "$d"/contigs.fa {output}; done
        rm {input.remove}
        """

rule skANI:
    input: 
        "results/assemblies/{sample}.fna"
    output: 
        "results/06_skani/skani_results_file.txt"
    params:
        extra= "-t 24 -n 1"
    log: 
        "logs/skani.log" 
    conda:
        "envs/skani.yml"
    shell:
        """
        skani search {input} -d /home/genomics/bioinf_databases/skani/skani-gtdb-r214-sketch-v0.2 -o {output} {params.extra} 2>> {log}
        """


rule Quast:
    input: 
       "results/assemblies/{sample}.fna" 
    output: 
        directory("results/07_quast/")
    conda:
        "envs/quast.yml"
    shell: 
        """
        for f in {input}; do quast.py "$f" -o {output}/$(basename "$f" .fna); done
        """

rule quast_summarie:
    input: 
       "results/assemblies/{sample}.fna" 
    output: 
        "results/07_quast/quast_summary_table.txt"
    params:
        header="Assembly\tcontigs (>= 0 bp)\tcontigs (>= 1000 bp)\tcontigs (>= 5000 bp)\tcontigs (>= 10000 bp)\tcontigs (>= 25000 bp)\tcontigs (>= 50000 bp)\tTotal length (>= 0 bp)\tTotal length (>= 1000 bp)\tTotal length (>= 5000 bp)\tTotal length (>= 10000 bp)\tTotal length (>= 25000 bp)\tTotal length (>= 50000 bp)\tcontigs\tLargest contig\tTotal length\tGC (%)\tN50\tN90\tauN\tL50\tL90\tN's per 100 kbp"
    shell:
        """
        # Create the output file and add the header
        echo -e "{params.header}" >> {output}

        # Initialize a counter for the number of files processed
        counter=0

        # Find and process all transposed_report.tsv files
        for file in $(find -type f -name "transposed_report.tsv"); do
            # Add the content of each file to the summary table (excluding the header)
            tail -n +2 "$file" >> {output}
            # Increment the counter
            counter=$((counter+1))
        done
    """

rule excel_and_beeswarm: 
    input:
        excel= "skani_quast_to_xlsx.py",
        beeswarm= "beeswarm_vis_assemblies.R",
        directory= "results/07_quast/",
        quast= "results/07_quast/quast_summary_table.txt"
    shell:
        """
        {input.excel} {input.directory}
        {input.beeswarm} {input.directory}{input.quast}
        """

rule Busco:
    input: 
        "results/assemblies/{sample}.fna" 
    output: 
        "results/08_busco/{sample}"
    params:
        extra= "-m genome --auto-lineage-prok -c 32"  
    conda:
        "envs/busco.yml"
    shell:
        """
        for sample in $(ls {input} | awk 'BEGIN{FS=".fna"}{print $1}'); do busco -i "$sample".fna -o {output} {params.extra} ; done
        """

rule Busco_visualisation:
    input:
        sample="results/08_busco/{sample}",
        script= "generate_plot.py"
    output:
        directory("results/busco_summaries")
    conda:
        "envs/busco.yml"
    shell:
        """
        cp {input.sample}/*/*/short_summary.specific.burkholderiales_odb10.*.txt {output}
        cd {output}
        for i in $(seq 1 15 $(ls -1 | wc -l)); do
            echo "Processing files $i to $((i+14))"
            mkdir -p part_"$i-$((i+14))"
            ls -1 | tail -n +$i | head -15 | while read file; do
                echo "Processing file: $file"
                mv "$file" part_"$i-$((i+14))"
            done
            {input.script} -wd part_"$i-$((i+14))"
        done
        """

